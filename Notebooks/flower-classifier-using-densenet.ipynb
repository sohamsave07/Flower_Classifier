{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.1.0\n"
     ]
    }
   ],
   "source": [
    "import math, re, os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n",
    "\n",
    "IMAGE_SIZE = [512, 512]\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "\n",
    "GCS_PATH_SELECT = { \n",
    "    192: GCS_DS_PATH + '/tfrecords-jpeg-192x192',\n",
    "    224: GCS_DS_PATH + '/tfrecords-jpeg-224x224',\n",
    "    331: GCS_DS_PATH + '/tfrecords-jpeg-331x331',\n",
    "    512: GCS_DS_PATH + '/tfrecords-jpeg-512x512'\n",
    "}\n",
    "GCS_PATH = GCS_PATH_SELECT[IMAGE_SIZE[0]]\n",
    "\n",
    "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\n",
    "VALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\n",
    "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec')\n",
    "\n",
    "CLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n",
    "           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n",
    "           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n",
    "           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n",
    "           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n",
    "           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n",
    "           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n",
    "           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n",
    "           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n",
    "           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n",
    "           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']                                                                                                                                               # 100-102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 12753 training images, 3712 validation images, 7382 unlabeled test images\n"
     ]
    }
   ],
   "source": [
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = tf.cast(example['class'], tf.int32)\n",
    "    return image, label # returns a dataset of (image, label) pairs\n",
    "\n",
    "def read_unlabeled_tfrecord(example):\n",
    "    UNLABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
    "        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    idnum = example['id']\n",
    "    return image, idnum # returns a dataset of image(s)\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
    "\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
    "    return dataset\n",
    "\n",
    "def data_augment(image, label):\n",
    "    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n",
    "    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n",
    "    # of the TPU while the TPU itself is computing gradients.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_saturation(image, 0, 2)\n",
    "    image = tf.image.random_brightness(image, 3)\n",
    "    image = tf.image.random_contrast(image, 0, 2)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_hue(image, 0.25)\n",
    "    return image, label   \n",
    "\n",
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(ordered=False):\n",
    "    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_test_dataset(ordered=False):\n",
    "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n",
    "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shapes:\n",
      "(128, 512, 512, 3) (128,)\n",
      "(128, 512, 512, 3) (128,)\n",
      "(128, 512, 512, 3) (128,)\n",
      "Training data label examples: [102  48  67  95  79  12   5  49   4   0   3  30  56  73  80   0  64   4\n",
      "  48 103  52  79  48  75  13  67  42  47   4  53  90  28   4  55  91  45\n",
      "  50  47   5 102  73 103  45  76  81  68  47  53  81 103   0  47  95  67\n",
      "  62  48  79  53  13  82  77  95  26  73  13  49  86  83  56   1  74  94\n",
      "  27  95  82 103  46 102  62   4 103  25  74  82  82  13  92  67  47 102\n",
      "  80  67  29   7  72  67  91  53  67  29  73  67  46  90  68   0  49  19\n",
      "  47  47   4  67 102  78  98  24  97  49  49   0  59  50  87  24 102  51\n",
      "  75  53]\n",
      "Validation data shapes:\n",
      "(128, 512, 512, 3) (128,)\n",
      "(128, 512, 512, 3) (128,)\n",
      "(128, 512, 512, 3) (128,)\n",
      "Validation data label examples: [ 50  56   4  77   0  72  67  73  16   0 102  46  48  74  52  86 103   4\n",
      "  14  51  48  24  50  81 103  14  58  73 103  87  87  87  45  84  36  70\n",
      "   4   4  72 103   4   2  48  53  71  95  37  64  76  49  78  85  29  42\n",
      "  19 103  10  99  31  76  73  53  42   4  80  54  96  77  50  80  48  84\n",
      "  82  41  73 103  45  67  51  78  53  86  73  57  30  52  67  88  22  11\n",
      "  53 103  52  48  14   4 103 103  75  53  67 103  39  48  95  70  46 102\n",
      "  75  18  52   4  28  55  67 102   5  77  45  75  49  86  67  71  53  83\n",
      "  89  68]\n",
      "Test data shapes:\n",
      "(128, 512, 512, 3) (128,)\n",
      "(128, 512, 512, 3) (128,)\n",
      "(128, 512, 512, 3) (128,)\n",
      "Test data IDs: ['f38eac7db' 'e33bff353' 'cda807af3' 'bf3116d78' '0a7989f52' '34d736b06'\n",
      " 'ada310267' '339430425' '8ed239a08' 'ef9591f3f' '1f750d4e6' 'f92de8523'\n",
      " 'a63f52d9e' '4d1ef02af' '6f88cabe1' '9ec15c151' 'd9924befc' '98e5cf2d2'\n",
      " '9a1e64ece' 'af70c8cc6' '99caeeea3' '366a3d04f' 'eec3f5ce2' '8f8ba278f'\n",
      " '6308fe124' 'e34772216' '776074cae' '630d3e7b9' 'f90c673f8' '5586807d4'\n",
      " '4165e5bec' '6a0b33f79' 'd7d866216' '0354bcfbb' 'dd754aab9' '209b4da16'\n",
      " '51493dac7' '85e1dd858' '3bf2347ab' '157be3bb4' '801d0d3c3' 'cc99ce5cc'\n",
      " 'b145fd2da' '10acd2f2c' '648319d0a' 'ce6b9b704' '675e1db7e' '367f31c9f'\n",
      " '03ac6694b' '10c508f77' 'f35bfd300' 'a99ec466c' '69a8e84ba' '94c8329af'\n",
      " '4f1f1670a' '665bfe8f5' '60e8a1d83' '5fccfc9b5' 'f553000bb' '5e0cdf39d'\n",
      " '3b9e7a8f5' '39df767ca' 'b5a739d1d' '8e5430d77' '260517e44' '75540546f'\n",
      " '6601f2903' '1972bae11' '0abb8d338' '613831ee6' 'cdb8be610' 'b5cc43bfa'\n",
      " '8ba970109' 'f5d022470' '826712f91' '707760045' '6f84aa228' 'dfbb8c112'\n",
      " '7d2f35248' 'f2db90ee7' 'c223fc7dd' '7163520df' '500c28291' '4dc902039'\n",
      " '2a872a9ef' '04d9215b3' '943eef63e' '95b5120db' 'ecf751fe5' 'a91e7f455'\n",
      " 'c46b163d8' '78ccf47e4' '5de6bcf29' '0fccb02fa' 'e1494fbde' '2a459a0aa'\n",
      " '328aba75f' 'dd0839e53' '7d6edd6f1' '8904c358d' 'd14992eb2' '35dbda91b'\n",
      " '50ff8f2d0' 'c5f4134e0' 'db86084d1' '8cf5bf4df' 'da9de3c05' '3b3341edb'\n",
      " '288feaf8f' '483a8e2d8' '7d2140905' '57a2e8995' '786172ac6' 'aeaf5ccbb'\n",
      " 'f16b615a7' '00c12e4ff' '2bc4dc850' 'b04f7be54' '97ddeaac9' 'da9ed562f'\n",
      " '27f69132b' '65b44f1fd' '329793680' '760d22629' 'fbfd88b1c' '2449b5518'\n",
      " '49f2b41a5' '61b1040d7']\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shapes:\")\n",
    "for image, label in get_training_dataset().take(3):\n",
    "    print(image.numpy().shape, label.numpy().shape)\n",
    "print(\"Training data label examples:\", label.numpy())\n",
    "print(\"Validation data shapes:\")\n",
    "for image, label in get_validation_dataset().take(3):\n",
    "    print(image.numpy().shape, label.numpy().shape)\n",
    "print(\"Validation data label examples:\", label.numpy())\n",
    "print(\"Test data shapes:\")\n",
    "for image, idnum in get_test_dataset().take(3):\n",
    "    print(image.numpy().shape, idnum.numpy().shape)\n",
    "print(\"Test data IDs:\", idnum.numpy().astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 22s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Model)          (None, 16, 16, 1920)      18321984  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 104)               199784    \n",
      "=================================================================\n",
      "Total params: 18,521,768\n",
      "Trainable params: 18,292,712\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    pretrained_model = tf.keras.applications.DenseNet201(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "    #pretrained_model = tf.keras.applications.Xception(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "    #pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "    pretrained_model.trainable = True # False = transfer learning, True = fine-tuning\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        pretrained_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
    "    ])\n",
    "        \n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate schedule: 1e-05 to 0.0004 to 1.18e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LR_START = 0.00001\n",
    "LR_MAX = 0.00005 * strategy.num_replicas_in_sync\n",
    "LR_MIN = 0.00001\n",
    "LR_RAMPUP_EPOCHS = 5\n",
    "LR_SUSTAIN_EPOCHS = 0\n",
    "LR_EXP_DECAY = .8\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
    "    return lr\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n",
    "\n",
    "rng = [i for i in range(25 if EPOCHS<25 else EPOCHS)]\n",
    "y = [lrfn(x) for x in rng]\n",
    "plt.plot(rng, y)\n",
    "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 99 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/30\n",
      "99/99 [==============================] - 424s 4s/step - loss: 4.4426 - sparse_categorical_accuracy: 0.0941 - val_loss: 4.0307 - val_sparse_categorical_accuracy: 0.2026\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 8.8e-05.\n",
      "Epoch 2/30\n",
      "99/99 [==============================] - 78s 792ms/step - loss: 2.4667 - sparse_categorical_accuracy: 0.4703 - val_loss: 1.4396 - val_sparse_categorical_accuracy: 0.6616\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.000166.\n",
      "Epoch 3/30\n",
      "99/99 [==============================] - 74s 748ms/step - loss: 1.2719 - sparse_categorical_accuracy: 0.7323 - val_loss: 0.7827 - val_sparse_categorical_accuracy: 0.7780\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.000244.\n",
      "Epoch 4/30\n",
      "99/99 [==============================] - 71s 716ms/step - loss: 0.8384 - sparse_categorical_accuracy: 0.8207 - val_loss: 0.7471 - val_sparse_categorical_accuracy: 0.8190\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000322.\n",
      "Epoch 5/30\n",
      "99/99 [==============================] - 76s 771ms/step - loss: 0.6828 - sparse_categorical_accuracy: 0.8314 - val_loss: 0.6658 - val_sparse_categorical_accuracy: 0.8211\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 6/30\n",
      "99/99 [==============================] - 76s 767ms/step - loss: 0.6083 - sparse_categorical_accuracy: 0.8422 - val_loss: 1.1396 - val_sparse_categorical_accuracy: 0.6918\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.000322.\n",
      "Epoch 7/30\n",
      "99/99 [==============================] - 73s 740ms/step - loss: 0.4325 - sparse_categorical_accuracy: 0.9116 - val_loss: 0.3966 - val_sparse_categorical_accuracy: 0.8815\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0002596000000000001.\n",
      "Epoch 8/30\n",
      "99/99 [==============================] - 71s 713ms/step - loss: 0.2954 - sparse_categorical_accuracy: 0.9261 - val_loss: 0.3660 - val_sparse_categorical_accuracy: 0.9181\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00020968000000000004.\n",
      "Epoch 9/30\n",
      "99/99 [==============================] - 69s 700ms/step - loss: 0.2378 - sparse_categorical_accuracy: 0.9426 - val_loss: 0.3365 - val_sparse_categorical_accuracy: 0.9116\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00016974400000000002.\n",
      "Epoch 10/30\n",
      "99/99 [==============================] - 77s 777ms/step - loss: 0.1763 - sparse_categorical_accuracy: 0.9672 - val_loss: 0.2814 - val_sparse_categorical_accuracy: 0.9310\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.00013779520000000003.\n",
      "Epoch 11/30\n",
      "99/99 [==============================] - 75s 753ms/step - loss: 0.1377 - sparse_categorical_accuracy: 0.9741 - val_loss: 0.2742 - val_sparse_categorical_accuracy: 0.9353\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.00011223616000000004.\n",
      "Epoch 12/30\n",
      "99/99 [==============================] - 72s 728ms/step - loss: 0.1029 - sparse_categorical_accuracy: 0.9703 - val_loss: 0.2702 - val_sparse_categorical_accuracy: 0.9397\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 9.178892800000003e-05.\n",
      "Epoch 13/30\n",
      "99/99 [==============================] - 70s 710ms/step - loss: 0.0927 - sparse_categorical_accuracy: 0.9861 - val_loss: 0.2615 - val_sparse_categorical_accuracy: 0.9375\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 7.543114240000003e-05.\n",
      "Epoch 14/30\n",
      "99/99 [==============================] - 76s 768ms/step - loss: 0.0758 - sparse_categorical_accuracy: 0.9842 - val_loss: 0.2545 - val_sparse_categorical_accuracy: 0.9397\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 6.234491392000002e-05.\n",
      "Epoch 15/30\n",
      "99/99 [==============================] - 76s 765ms/step - loss: 0.0797 - sparse_categorical_accuracy: 0.9912 - val_loss: 0.2488 - val_sparse_categorical_accuracy: 0.9461\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 5.1875931136000024e-05.\n",
      "Epoch 16/30\n",
      "99/99 [==============================] - 72s 730ms/step - loss: 0.0675 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.2462 - val_sparse_categorical_accuracy: 0.9504\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 4.3500744908800015e-05.\n",
      "Epoch 17/30\n",
      "99/99 [==============================] - 71s 722ms/step - loss: 0.0645 - sparse_categorical_accuracy: 0.9848 - val_loss: 0.2459 - val_sparse_categorical_accuracy: 0.9504\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 3.6800595927040014e-05.\n",
      "Epoch 18/30\n",
      "99/99 [==============================] - 76s 763ms/step - loss: 0.0575 - sparse_categorical_accuracy: 0.9893 - val_loss: 0.2438 - val_sparse_categorical_accuracy: 0.9461\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 3.1440476741632015e-05.\n",
      "Epoch 19/30\n",
      "99/99 [==============================] - 76s 771ms/step - loss: 0.0491 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.2488 - val_sparse_categorical_accuracy: 0.9461\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 2.7152381393305616e-05.\n",
      "Epoch 20/30\n",
      "99/99 [==============================] - 73s 737ms/step - loss: 0.0519 - sparse_categorical_accuracy: 0.9855 - val_loss: 0.2494 - val_sparse_categorical_accuracy: 0.9504\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 2.3721905114644494e-05.\n",
      "Epoch 21/30\n",
      "99/99 [==============================] - 71s 721ms/step - loss: 0.0492 - sparse_categorical_accuracy: 0.9912 - val_loss: 0.2529 - val_sparse_categorical_accuracy: 0.9504\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 2.0977524091715595e-05.\n",
      "Epoch 22/30\n",
      "99/99 [==============================] - 70s 707ms/step - loss: 0.0475 - sparse_categorical_accuracy: 0.9937 - val_loss: 0.2534 - val_sparse_categorical_accuracy: 0.9483\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1.8782019273372477e-05.\n",
      "Epoch 23/30\n",
      "99/99 [==============================] - 76s 770ms/step - loss: 0.0443 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.2504 - val_sparse_categorical_accuracy: 0.9461\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1.702561541869798e-05.\n",
      "Epoch 24/30\n",
      "99/99 [==============================] - 74s 752ms/step - loss: 0.0437 - sparse_categorical_accuracy: 0.9931 - val_loss: 0.2460 - val_sparse_categorical_accuracy: 0.9504\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.5620492334958385e-05.\n",
      "Epoch 25/30\n",
      "99/99 [==============================] - 72s 726ms/step - loss: 0.0420 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.2461 - val_sparse_categorical_accuracy: 0.9504\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 1.4496393867966709e-05.\n",
      "Epoch 26/30\n",
      "99/99 [==============================] - 71s 714ms/step - loss: 0.0422 - sparse_categorical_accuracy: 0.9912 - val_loss: 0.2486 - val_sparse_categorical_accuracy: 0.9526\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 1.3597115094373368e-05.\n",
      "Epoch 27/30\n",
      "99/99 [==============================] - 75s 757ms/step - loss: 0.0357 - sparse_categorical_accuracy: 0.9931 - val_loss: 0.2445 - val_sparse_categorical_accuracy: 0.9526\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 1.2877692075498695e-05.\n",
      "Epoch 28/30\n",
      "99/99 [==============================] - 76s 763ms/step - loss: 0.0393 - sparse_categorical_accuracy: 0.9912 - val_loss: 0.2461 - val_sparse_categorical_accuracy: 0.9526\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 1.2302153660398955e-05.\n",
      "Epoch 29/30\n",
      "99/99 [==============================] - 72s 732ms/step - loss: 0.0451 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.2467 - val_sparse_categorical_accuracy: 0.9504\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1.1841722928319164e-05.\n",
      "Epoch 30/30\n",
      "99/99 [==============================] - 71s 714ms/step - loss: 0.0468 - sparse_categorical_accuracy: 0.9943 - val_loss: 0.2468 - val_sparse_categorical_accuracy: 0.9504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1c3bb240b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(get_training_dataset(), steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS, callbacks=[lr_callback], validation_data=get_validation_dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions...\n",
      "[ 67  28  83 ...  53 102  62]\n",
      "Generating submission.csv file...\n",
      "id,label\r\n",
      "252d840db,67\r\n",
      "1c4736dea,28\r\n",
      "c37a6f3e9,83\r\n",
      "00e4f514e,103\r\n",
      "59d1b6146,70\r\n",
      "8d808a07b,53\r\n",
      "aeb67eefb,52\r\n",
      "53cfc6586,48\r\n",
      "aaa580243,82\r\n"
     ]
    }
   ],
   "source": [
    "test_ds = get_test_dataset(ordered=True)\n",
    "\n",
    "print('Computing predictions...')\n",
    "test_images_ds = test_ds.map(lambda image, idnum: image)\n",
    "probabilities = model.predict(test_images_ds)\n",
    "predictions = np.argmax(probabilities, axis=-1)\n",
    "print(predictions)\n",
    "\n",
    "print('Generating submission.csv file...')\n",
    "test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n",
    "test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\n",
    "np.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=['%s', '%d'], delimiter=',', header='id,label', comments='')\n",
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
