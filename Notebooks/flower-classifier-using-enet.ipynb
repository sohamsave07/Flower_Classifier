{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -q efficientnet\n",
    "import math, re, os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import efficientnet.tfkeras as efn\n",
    "from matplotlib import pyplot as plt\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n",
    "\n",
    "IMAGE_SIZE = [512, 512]\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "\n",
    "GCS_PATH_SELECT = { \n",
    "    192: GCS_DS_PATH + '/tfrecords-jpeg-192x192',\n",
    "    224: GCS_DS_PATH + '/tfrecords-jpeg-224x224',\n",
    "    331: GCS_DS_PATH + '/tfrecords-jpeg-331x331',\n",
    "    512: GCS_DS_PATH + '/tfrecords-jpeg-512x512'\n",
    "}\n",
    "GCS_PATH = GCS_PATH_SELECT[IMAGE_SIZE[0]]\n",
    "\n",
    "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\n",
    "VALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\n",
    "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec')\n",
    "\n",
    "CLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n",
    "           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n",
    "           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n",
    "           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n",
    "           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n",
    "           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n",
    "           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n",
    "           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n",
    "           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n",
    "           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n",
    "           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']                                                                                                                                               # 100-102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 12753 training images, 3712 validation images, 7382 unlabeled test images\n"
     ]
    }
   ],
   "source": [
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = tf.cast(example['class'], tf.int32)\n",
    "    return image, label # returns a dataset of (image, label) pairs\n",
    "\n",
    "def read_unlabeled_tfrecord(example):\n",
    "    UNLABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
    "        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    idnum = example['id']\n",
    "    return image, idnum # returns a dataset of image(s)\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
    "\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
    "    return dataset\n",
    "\n",
    "def data_augment(image, label):\n",
    "    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n",
    "    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n",
    "    # of the TPU while the TPU itself is computing gradients.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_saturation(image, 0, 2)\n",
    "    image = tf.image.random_brightness(image, 3)\n",
    "    image = tf.image.random_contrast(image, 0, 2)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_hue(image, 0.25)\n",
    "    return image, label   \n",
    "\n",
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(ordered=False):\n",
    "    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_test_dataset(ordered=False):\n",
    "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n",
    "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shapes:\n",
      "(128, 512, 512, 3) (128,)\n",
      "(128, 512, 512, 3) (128,)\n",
      "(128, 512, 512, 3) (128,)\n",
      "Training data label examples: [ 14  75  49  67  77  53  90  75  96  67   1  73  78  49  17  91  95  74\n",
      "   2  24  53   0  67  73  48  67  49  80  96  67  67  88  86  67  49  28\n",
      "  49  24  75  22  43 103  67 102  50  50  42  48  96 103  29  80  70  47\n",
      "  67   4   4  53  83  14  81  22   4  72  67  73  67 102   8  18  67  83\n",
      "  47  67  70   4  94  42  29  71   9   4 103  29  75 102  63  73  67  86\n",
      "  51  49   4  67  49  91  71  48  76  73   4  39  81  49  10   4  82  17\n",
      "  91 103 103   4  83   4   4  29  68  47   4 102 103  83  30  37  25   5\n",
      " 103  50]\n",
      "Validation data shapes:\n",
      "(128, 512, 512, 3) (128,)\n",
      "(128, 512, 512, 3) (128,)\n",
      "(128, 512, 512, 3) (128,)\n",
      "Validation data label examples: [ 55   5  49  83  35  80   4   4  68  48  49  62  77  75  95   0   4  59\n",
      "  52  45  74 102 103  67  96  53  53  90  73  47  50  78  41  73  46  36\n",
      "  29 103 103  49  73  72 103  13  73   4  53  53  72  67  29   8  87  47\n",
      " 102  73  69  50  49   4  98  49   1  80  29   4  87  95 103  39 103  69\n",
      " 100  73 103 103   9  77  18  55  45  20 103  82   4 103  48  86  13  47\n",
      " 103  41  32  43  14  75  78   4  47 102  75  67  90  95  15  73  76   4\n",
      "  78  94  53  40 103 103  68  79  18  53  73 103 102  93   4 103  73  49\n",
      "  48  87]\n",
      "Test data shapes:\n",
      "(128, 512, 512, 3) (128,)\n",
      "(128, 512, 512, 3) (128,)\n",
      "(128, 512, 512, 3) (128,)\n",
      "Test data IDs: ['b87e16bc0' 'd8437a7f7' '981396649' '85c2ca274' 'f7019798c' 'b738a5ab0'\n",
      " '931b0b249' 'd35565c6c' '6fc119103' '7725cb554' 'f0727012b' '7b53e5791'\n",
      " 'ce5af8fc3' 'aaab6a867' 'dd9cf65da' '13d3c108e' '34cc8d691' 'e93da9242'\n",
      " '46241640f' 'c77e635e6' '0befbdd9e' 'b05b5e5ed' '7484473e0' 'cffa6d1a4'\n",
      " 'b811b25c9' 'bb15fd515' 'ce1019f58' 'cc0e98f9c' 'd83d3fbab' '1691d45e6'\n",
      " '026d4082b' '4fdd76274' 'a2fcedaf7' '62e32ec91' 'ed8c3c3f8' '7dc69b4eb'\n",
      " 'b7c137651' 'c4d436848' '07ccfbc89' 'a0c7302d1' '1eba038ad' 'a7caedcb0'\n",
      " '92673a9aa' '8128b8af9' '8a8eefe09' 'ce6303fec' 'aa560af38' '9ed2586ca'\n",
      " 'a64d32c6a' 'a10a0b280' '3d95467fe' 'b145790f2' 'e9a2109c0' '7593bf7d9'\n",
      " '09adc5faa' '1314201bc' '787578be9' '719a12da9' '4d178a6b4' '47c4e4fce'\n",
      " '903a3ee76' '94a7c5ed2' '3c5103dc0' '11db2e1d4' 'e2e81b2c4' 'cfdfb9028'\n",
      " '4e7bdb1cb' '8ccdebad5' '440daa96f' '953076db7' 'a98328317' '32d710e55'\n",
      " 'e0098a158' '1a5d9c089' '0ae82a090' '364e07591' '73a3ae7ee' '599d64d01'\n",
      " '410639882' '5b87d8d4b' '63eb884ce' '1ff3a322b' '627f0996d' 'eb2216bf9'\n",
      " '885f2eac5' 'f4cd5efa6' '42b0abd95' '1b07b0a53' 'bbad1c1a8' 'b6cb0c2b8'\n",
      " '0f6325318' '03af10094' '462a4b1f1' 'd4350350c' '7472f2db4' 'f5aa796ed'\n",
      " '4eac8e323' '50c36b121' '92be2245d' '1a0fb01d4' 'd2927e981' 'de4b24dec'\n",
      " '2043fd8b7' '464ee7908' 'f0e6a679a' '87acecd2a' '3962a6493' 'acd745458'\n",
      " '8d73023b6' '9c5095d94' '74f0d70ef' 'dc826db21' '2ceabb5ef' '750bae291'\n",
      " '29add8561' '00e3084c1' 'd91b12e12' '81d39b116' '9b2c62063' '677dcf9b6'\n",
      " 'fc2f9869f' 'c38903943' 'e6c5fe236' '5817b58d8' '9d3f09890' '1c8122f7e'\n",
      " 'e8475ad43' '6e74639ff']\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shapes:\")\n",
    "for image, label in get_training_dataset().take(3):\n",
    "    print(image.numpy().shape, label.numpy().shape)\n",
    "print(\"Training data label examples:\", label.numpy())\n",
    "print(\"Validation data shapes:\")\n",
    "for image, label in get_validation_dataset().take(3):\n",
    "    print(image.numpy().shape, label.numpy().shape)\n",
    "print(\"Validation data label examples:\", label.numpy())\n",
    "print(\"Test data shapes:\")\n",
    "for image, idnum in get_test_dataset().take(3):\n",
    "    print(image.numpy().shape, idnum.numpy().shape)\n",
    "print(\"Test data IDs:\", idnum.numpy().astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b7_noisy-student_notop.h5\n",
      "258072576/258068648 [==============================] - 4s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b7 (Model)      (None, 16, 16, 2560)      64097680  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 104)               266344    \n",
      "=================================================================\n",
      "Total params: 64,364,024\n",
      "Trainable params: 64,053,304\n",
      "Non-trainable params: 310,720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    #pretrained_model = tf.keras.applications.DenseNet201(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "    #pretrained_model = tf.keras.applications.Xception(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "    #pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "    pretrained_model = efn.EfficientNetB7(weights='noisy-student', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n",
    "    pretrained_model.trainable = True # False = transfer learning, True = fine-tuning\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        pretrained_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
    "    ])\n",
    "        \n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate schedule: 1e-05 to 0.0004 to 1.18e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LR_START = 0.00001\n",
    "LR_MAX = 0.00005 * strategy.num_replicas_in_sync\n",
    "LR_MIN = 0.00001\n",
    "LR_RAMPUP_EPOCHS = 5\n",
    "LR_SUSTAIN_EPOCHS = 0\n",
    "LR_EXP_DECAY = .8\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
    "    return lr\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n",
    "\n",
    "rng = [i for i in range(25 if EPOCHS<25 else EPOCHS)]\n",
    "y = [lrfn(x) for x in rng]\n",
    "plt.plot(rng, y)\n",
    "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 99 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/30\n",
      "99/99 [==============================] - 431s 4s/step - loss: 4.6090 - sparse_categorical_accuracy: 0.0423 - val_loss: 4.6207 - val_sparse_categorical_accuracy: 0.0172\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 8.8e-05.\n",
      "Epoch 2/30\n",
      "99/99 [==============================] - 112s 1s/step - loss: 3.8162 - sparse_categorical_accuracy: 0.2014 - val_loss: 2.8095 - val_sparse_categorical_accuracy: 0.3578\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.000166.\n",
      "Epoch 3/30\n",
      "99/99 [==============================] - 103s 1s/step - loss: 2.0841 - sparse_categorical_accuracy: 0.5164 - val_loss: 0.9047 - val_sparse_categorical_accuracy: 0.7737\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.000244.\n",
      "Epoch 4/30\n",
      "99/99 [==============================] - 108s 1s/step - loss: 1.0889 - sparse_categorical_accuracy: 0.7247 - val_loss: 0.5041 - val_sparse_categorical_accuracy: 0.8664\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000322.\n",
      "Epoch 5/30\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.7764 - sparse_categorical_accuracy: 0.7980 - val_loss: 0.3667 - val_sparse_categorical_accuracy: 0.8879\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 6/30\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.6178 - sparse_categorical_accuracy: 0.8472 - val_loss: 0.3593 - val_sparse_categorical_accuracy: 0.8879\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.000322.\n",
      "Epoch 7/30\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.4736 - sparse_categorical_accuracy: 0.8870 - val_loss: 0.2756 - val_sparse_categorical_accuracy: 0.9310\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0002596000000000001.\n",
      "Epoch 8/30\n",
      "99/99 [==============================] - 103s 1s/step - loss: 0.3520 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.2440 - val_sparse_categorical_accuracy: 0.9375\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00020968000000000004.\n",
      "Epoch 9/30\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.3008 - sparse_categorical_accuracy: 0.9186 - val_loss: 0.2328 - val_sparse_categorical_accuracy: 0.9332\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00016974400000000002.\n",
      "Epoch 10/30\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.2440 - sparse_categorical_accuracy: 0.9324 - val_loss: 0.2368 - val_sparse_categorical_accuracy: 0.9461\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.00013779520000000003.\n",
      "Epoch 11/30\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.1990 - sparse_categorical_accuracy: 0.9514 - val_loss: 0.2216 - val_sparse_categorical_accuracy: 0.9418\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.00011223616000000004.\n",
      "Epoch 12/30\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.1786 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.2162 - val_sparse_categorical_accuracy: 0.9461\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 9.178892800000003e-05.\n",
      "Epoch 13/30\n",
      "99/99 [==============================] - 104s 1s/step - loss: 0.1561 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.2139 - val_sparse_categorical_accuracy: 0.9483\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 7.543114240000003e-05.\n",
      "Epoch 14/30\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.1444 - sparse_categorical_accuracy: 0.9628 - val_loss: 0.2112 - val_sparse_categorical_accuracy: 0.9440\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 6.234491392000002e-05.\n",
      "Epoch 15/30\n",
      "99/99 [==============================] - 110s 1s/step - loss: 0.1387 - sparse_categorical_accuracy: 0.9729 - val_loss: 0.2201 - val_sparse_categorical_accuracy: 0.9504\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 5.1875931136000024e-05.\n",
      "Epoch 16/30\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.1262 - sparse_categorical_accuracy: 0.9735 - val_loss: 0.2086 - val_sparse_categorical_accuracy: 0.9440\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 4.3500744908800015e-05.\n",
      "Epoch 17/30\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.1181 - sparse_categorical_accuracy: 0.9672 - val_loss: 0.2117 - val_sparse_categorical_accuracy: 0.9504\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 3.6800595927040014e-05.\n",
      "Epoch 18/30\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.1197 - sparse_categorical_accuracy: 0.9760 - val_loss: 0.2111 - val_sparse_categorical_accuracy: 0.9504\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 3.1440476741632015e-05.\n",
      "Epoch 19/30\n",
      "99/99 [==============================] - 106s 1s/step - loss: 0.1235 - sparse_categorical_accuracy: 0.9691 - val_loss: 0.2156 - val_sparse_categorical_accuracy: 0.9483\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 2.7152381393305616e-05.\n",
      "Epoch 20/30\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.1056 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.2134 - val_sparse_categorical_accuracy: 0.9504\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 2.3721905114644494e-05.\n",
      "Epoch 21/30\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.0992 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.2151 - val_sparse_categorical_accuracy: 0.9440\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 2.0977524091715595e-05.\n",
      "Epoch 22/30\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.0982 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.2157 - val_sparse_categorical_accuracy: 0.9461\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1.8782019273372477e-05.\n",
      "Epoch 23/30\n",
      "99/99 [==============================] - 109s 1s/step - loss: 0.0993 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.2139 - val_sparse_categorical_accuracy: 0.9418\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1.702561541869798e-05.\n",
      "Epoch 24/30\n",
      "99/99 [==============================] - 103s 1s/step - loss: 0.0898 - sparse_categorical_accuracy: 0.9735 - val_loss: 0.2133 - val_sparse_categorical_accuracy: 0.9418\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.5620492334958385e-05.\n",
      "Epoch 25/30\n",
      "69/99 [===================>..........] - ETA: 2:49 - loss: 0.0985 - sparse_categorical_accuracy: 0.9688"
     ]
    },
    {
     "ename": "AbortedError",
     "evalue": "debug dump triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAbortedError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2b50abba8f40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_training_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_validation_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m                       total_epochs=1)\n\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m--> 397\u001b[0;31m                                  prefix='val_')\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    769\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1394\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m     \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3239\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3242\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_in_graph_mode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3243\u001b[0m     \u001b[0;31m# This is a variable which was created in an eager context, but is being\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/values.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m       raise NotImplementedError(\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \"\"\"\n\u001b[1;32m    941\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    908\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mAbortedError\u001b[0m: debug dump triggered"
     ]
    }
   ],
   "source": [
    "model.fit(get_training_dataset(), steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS, callbacks=[lr_callback], validation_data=get_validation_dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions...\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "stream did not block host until done; was already in an error state [Op:MakeIterator]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-589f7632a50c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Computing predictions...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_images_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midnum\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m           model, mode)\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m       callbacks = cbks.configure_callbacks(\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     worker_iterators = _create_iterators_per_worker(self._cloned_datasets,\n\u001b[0;32m--> 565\u001b[0;31m                                                     self._input_workers)\n\u001b[0m\u001b[1;32m    566\u001b[0m     iterator = DistributedIterator(self._input_workers, worker_iterators,\n\u001b[1;32m    567\u001b[0m                                    self._strategy)\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m_create_iterators_per_worker\u001b[0;34m(worker_datasets, input_workers)\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0mworker_devices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_devices_for_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m       iterator = _SingleWorkerDatasetIterator(worker_datasets[i], worker,\n\u001b[0;32m-> 1011\u001b[0;31m                                               worker_devices)\n\u001b[0m\u001b[1;32m   1012\u001b[0m       \u001b[0miterators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0miterators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, worker, devices)\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_devices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_make_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m_make_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       self._iterator = multi_device_iterator_ops.MultiDeviceIterator(\n\u001b[0;32m--> 870\u001b[0;31m           self._dataset, self._devices)\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/data/ops/multi_device_iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, devices, max_buffer_size, prefetch_buffer_size, source_device)\u001b[0m\n\u001b[1;32m    292\u001b[0m                                     self._experimental_slack)\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_iterators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m           self._device_iterators.append(\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmake_one_shot_iterator\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m   2479\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDatasetV1Adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_make_one_shot_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2057\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_make_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0m_ensure_same_dataset_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    592\u001b[0m           context.context().device_spec.device_type != \"CPU\"):\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    617\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 619\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   2703\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2704\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2705\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: stream did not block host until done; was already in an error state [Op:MakeIterator]"
     ]
    }
   ],
   "source": [
    "test_ds = get_test_dataset(ordered=True)\n",
    "\n",
    "print('Computing predictions...')\n",
    "test_images_ds = test_ds.map(lambda image, idnum: image)\n",
    "probabilities = model.predict(test_images_ds)\n",
    "predictions = np.argmax(probabilities, axis=-1)\n",
    "print(predictions)\n",
    "\n",
    "print('Generating submission.csv file...')\n",
    "test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n",
    "test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\n",
    "np.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=['%s', '%d'], delimiter=',', header='id,label', comments='')\n",
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
