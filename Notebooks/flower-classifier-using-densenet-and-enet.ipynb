{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.1.0\n"
     ]
    }
   ],
   "source": [
    "import math, re, os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU grpc://10.0.0.2:8470\n",
      "REPLICAS 8\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print(\"Running on TPU\", tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "else:\n",
    "    startegy = tf.distribute.get_strategy()\n",
    "    \n",
    "print(\"REPLICAS\", strategy.num_replicas_in_sync)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path('flower-classification-with-tpus')\n",
    "\n",
    "IMAGE_SIZE = [512, 512]\n",
    "\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "\n",
    "GCS_PATH_SELECT = { # available image sizes\n",
    "    192: GCS_DS_PATH + '/tfrecords-jpeg-192x192/',\n",
    "    224: GCS_DS_PATH + '/tfrecords-jpeg-224x224/',\n",
    "    331: GCS_DS_PATH + '/tfrecords-jpeg-331x331/',\n",
    "    512: GCS_DS_PATH + '/tfrecords-jpeg-512x512/'\n",
    "}\n",
    "GCS_PATH = GCS_PATH_SELECT[IMAGE_SIZE[0]]\n",
    "\n",
    "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + 'train/*.tfrec')\n",
    "VALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + 'val/*.tfrec')\n",
    "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + 'test/*.tfrec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path('oxford-flowers-tfrecords')\n",
    "\n",
    "IMAGE_SIZE = [512, 512] \n",
    "\n",
    "BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n",
    "\n",
    "GCS_PATH_SELECT = { # available image sizes\n",
    "    192: GCS_DS_PATH + '/tfrecords-png-192x192/',\n",
    "    224: GCS_DS_PATH + '/tfrecords-png-224x224/',\n",
    "    331: GCS_DS_PATH + '/tfrecords-png-331x331/',\n",
    "    512: GCS_DS_PATH + '/tfrecords-png-512x512/'\n",
    "}\n",
    "GCS_PATH = GCS_PATH_SELECT[IMAGE_SIZE[0]]\n",
    "\n",
    "TRAINING_FILENAMES += tf.io.gfile.glob(GCS_PATH + '*.tfrec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n",
    "           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n",
    "           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n",
    "           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n",
    "           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n",
    "           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n",
    "           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n",
    "           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n",
    "           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n",
    "           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n",
    "           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']                                                                                                                                               # 100 - 102\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 20942 training images, 3712 validation images, 7382 unlabeled test images\n"
     ]
    }
   ],
   "source": [
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = tf.cast(example['class'], tf.int32)\n",
    "    return image, label # returns a dataset of (image, label) pairs\n",
    "\n",
    "def read_unlabeled_tfrecord(example):\n",
    "    UNLABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
    "        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    idnum = example['id']\n",
    "    return image, idnum # returns a dataset of image(s)\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
    "\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
    "    return dataset\n",
    "\n",
    "def data_augment(image, label):\n",
    "    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n",
    "    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n",
    "    # of the TPU while the TPU itself is computing gradients.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_saturation(image, 0, 2)\n",
    "    image = tf.image.random_brightness(image, 3)\n",
    "    image = tf.image.random_contrast(image, 0, 2)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_hue(image, 0.25)\n",
    "    return image, label   \n",
    "\n",
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(ordered=False):\n",
    "    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_test_dataset(ordered=False):\n",
    "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n",
    "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shapes:\n",
      "(256, 512, 512, 3) (256,)\n",
      "(256, 512, 512, 3) (256,)\n",
      "(256, 512, 512, 3) (256,)\n",
      "Training data label examples: [ 67  71  36  68  23  76   4  49  83  50  77  84  67 103  14  47  53  73\n",
      "   9   0  79  87  68  47  53  75  50  50 102  73  70  80   5  73  39 103\n",
      "  30  28 103  77  49   0  42  81  50  28   4  60  73 103  49   9  75   5\n",
      "  57  25  48  59  69  58  24   0 103 102  49  20  73  49 102  73  75  95\n",
      " 102  51  62 103  81  77  67  53  67  28  67  95  73  77  76  60  28  73\n",
      "  57   4  56  90  66 103  75  21   4  67  67  79  14 103  72  13  67   4\n",
      "  18  75  36  28   6  67  76  90  70   0  23  72  83  67  30  48  82   7\n",
      "  67  46  47  28  78  75  81  75  76  59  52 103  52  14  68  49  88   8\n",
      "  73  74  75  89   4  93  73  27  41  75  22   3  67  14  13  64 103  17\n",
      "  14 101   0  12   4  49  46  18   4   4  29  53  71  67  70  67  93  67\n",
      "  59  79  12  68  87  67 103  75  81  73  94 103  21  61  83  67  77  53\n",
      "  41  45  38  93  36  75  48   4  47  53  82  80  53   8  30  55  35  67\n",
      "  41  91  92  69  29  16  10  83  67  28  67  50 103  17  77   5   4   4\n",
      "  67   5  29 102   4  41  71  49 103 103  12  96  22  50  53  93  56  67\n",
      "  93  40  71  52]\n",
      "Validation data shapes:\n",
      "(256, 512, 512, 3) (256,)\n",
      "(256, 512, 512, 3) (256,)\n",
      "(256, 512, 512, 3) (256,)\n",
      "Validation data label examples: [ 75  49  68  28  13 103  12 102  91  55  51  67  84  65 102   4  91  86\n",
      "  49  46  53  39  34  73 103  73 102  26 102  47  47  49 102  53  75  50\n",
      "  68  67  75   4  95  56  90  96 102  47  49  67  77  73  70  15  48  18\n",
      "  91   0  53  90  73  49  39  18  67 103   5  82  91  86  82  39   0  79\n",
      "  30  68  87  51   7  46  80  74  70  79  71  81  49  62  74  25  67  12\n",
      " 102   4  73  45 103   4  24  58  33  41  67  87  67  70  24  10   0  40\n",
      "  77   2  72  14  14 101  10 103  41  78  76  48  87  84  75  53  82  67\n",
      "  29  70  87  84  47   5   4  77  52  19  44  72  70  45   4  14  47  73\n",
      "  99  48  74   4 102  25  69  68  98  73  67  53  53  49  67  80 103  28\n",
      "   4  23  71  76  75  43  12  67 103  96  91 103 103  67 102  93 103  83\n",
      "  80  43  90  31  67  86  73  76   4  84  12 103  53  11   7  53  14   1\n",
      "  41  83  28  80   4  13 103  13  77  45  99  69  77  82 103 102  53 103\n",
      "  78  12   4  48  18  48  67 103  49  30 103   4  73   4 102  53 103  72\n",
      "  11  70  82  67  52  47  67  49  48  14  95   4  86  47  67  73  48  90\n",
      "  53  13  67  67]\n",
      "Test data shapes:\n",
      "(256, 512, 512, 3) (256,)\n",
      "(256, 512, 512, 3) (256,)\n",
      "(256, 512, 512, 3) (256,)\n",
      "Test data IDs: ['c223fc7dd' '8d94bd8b9' '500c28291' '2a872a9ef' '943eef63e' 'c46b163d8'\n",
      " '5de6bcf29' 'e1494fbde' '328aba75f' '7d6edd6f1' '490efc553' 'd14992eb2'\n",
      " 'e9d6bf3cb' '35dbda91b' 'c0edbe84c' 'c5f4134e0' '8cf5bf4df' 'd4a2a2f29'\n",
      " '3b3341edb' '4c0f2c1ad' '483a8e2d8' '57a2e8995' 'aeaf5ccbb' '00c12e4ff'\n",
      " 'b04f7be54' 'da9ed562f' '329793680' 'fbfd88b1c' '2449b5518' '56a71117b'\n",
      " '6759ac31a' '7b506b5bd' 'f2a35c7cd' '07b1b52f5' '61b1040d7' 'd0a654445'\n",
      " 'a2d9d460e' 'ac1af6f95' '029c37998' '9a879fb6d' '805e9a7b0' 'd7c723881'\n",
      " '7605a3733' 'e1e5687f0' 'c210cba33' 'f509e2cff' '14a804b2f' '9d051fef4'\n",
      " '47830a2a1' '582a4afd0' '6e16e769d' '73d04b4a0' 'f85c3cd52' '5f8f53f23'\n",
      " '5f2c16024' '6dbf25622' '4028851f0' '30bfe5b05' '89f3b6297' '3231b476a'\n",
      " 'e810fbb6b' '2e211accd' '2b47bed50' '15bcf0bc5' '8965a61bc' '54eb01070'\n",
      " 'f5a7cbd09' '1eb6f22d5' '68d5dc3c5' '154f5a75b' '5ca912390' '52491f753'\n",
      " '52dd86f38' 'cdcb45570' '881336587' '7b38952f6' '6021f47e4' '12fdb3200'\n",
      " '97dbf9d67' 'f1b51e257' '929ac8834' '7d1005a2c' 'baf415f07' '7f5479556'\n",
      " 'a007c4ce7' 'e955870c5' '14024c433' '3b7c11d3e' '0fdb2e372' '9cb5c3012'\n",
      " 'b448720a0' 'cf087fd47' '3ba519bb8' '2406dc526' 'd01d8d2fd' 'a1d2cd9b9'\n",
      " 'f2defaf74' '23e9b2025' 'b687e4bd9' 'fd5eb7e8c' '2c670a497' '98b1475af'\n",
      " '3526d7815' '6433f1917' '34438649b' '3feba0f46' 'c12330d34' '9ae160f11'\n",
      " 'ea602cdc8' '92782ef45' '9944acf36' '3f7fa081c' '45a702ee8' '92a289926'\n",
      " '78bd1cad3' 'cc98ccc8d' '92aea1584' 'd81c315b3' '3dd3823ba' '4434ef42e'\n",
      " 'e64bd2b5f' '8967f7f3b' 'fe195b05f' '21a0ef857' 'cb80e17f2' '9367b53dc'\n",
      " '471609fe8' '086d87731' '261838dd1' '67fa9ad3f' 'f8bffd3d7' 'd0a99b293'\n",
      " '5e287a0e3' 'c980fa8a5' '9eaf1170e' 'f302f29a2' '78a91fc04' 'd852da76f'\n",
      " '9b7ad01b5' '922e45d33' '3070a069b' 'e6c3f8ec8' 'fc4e189da' '43a84d203'\n",
      " '64581ef78' 'a8de792e9' '4e4504ced' '42ed99f8b' '70501f63a' '351f462dc'\n",
      " '3863b7205' 'abb6d81d5' 'c9d5ec522' 'd974a8a25' '410641125' 'e69a97f86'\n",
      " '985c8a491' '1dbaa5744' '90a369187' '69a2f544d' '6b57e5a58' '7cc60fb22'\n",
      " 'baf87d0e3' 'c4a376520' '80abd878b' 'f92ea03e2' '1c7354786' '5345fc847'\n",
      " '3e7ae2503' 'c3c540406' '1abc6d06e' '1f2621b4c' 'b3cf1a86f' '690f47487'\n",
      " '30c74817b' '37377ab6b' '6e1842cc3' '6abdbbd7d' '817066a16' '48e65f113'\n",
      " '0dbbde2b4' '724560f8b' '7cff9aa7b' '8e8f25c31' '492569251' 'b104b01c3'\n",
      " 'ebd745005' 'e53134336' 'a94c4d821' 'c09ec978c' '4bfdc5664' 'dd7ae60d1'\n",
      " 'e028101c5' '78235a81d' 'fef9f8524' '8361e9b86' '57c274565' '9980474e3'\n",
      " 'a534b0f16' '450dd240e' 'e7b039312' 'cecb3fe1c' '9403b3f86' '014809654'\n",
      " '5bc0988c2' 'e3fc821ef' 'b731c25d6' 'a07779d6c' 'd8f1c6f49' 'be007fe7e'\n",
      " '5a5cc97ec' 'fdaf286c6' 'a82ca5b13' 'fd3fb66f0' '3d6f46c76' '3d5479aca'\n",
      " 'a76840623' '29ee6d680' '7514c8182' 'b5eb21e9c' 'f80f02286' '13fff11ed'\n",
      " 'ad494795d' 'e26d85d35' 'dc8dc1ad0' 'f6d873abc' '74bec8798' 'aeb67eefb'\n",
      " 'fd3bba010' '2213dd7ad' '8cccd4aa7' 'edecaff0a' '9af5f572d' '37e16acde'\n",
      " '12d007adc' '054412f7e' '1548838d2' '16ad94559' '5ac870ba2' 'f63a9b6fa'\n",
      " 'bb0b9304e' 'd97215599' 'debf90490' '034ef87a4' '416e24d42' '0394a004e'\n",
      " 'abed810c6' '444a5e9fe' 'e1e7f8c61' 'ec55c0f86' 'f85a5ee9a' '7cb5e6b99'\n",
      " '6b82e86e7' '358cb6a28' '6557acff6' 'dd20b2594']\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shapes:\")\n",
    "for image, label in get_training_dataset().take(3):\n",
    "    print(image.numpy().shape, label.numpy().shape)\n",
    "print(\"Training data label examples:\", label.numpy())\n",
    "print(\"Validation data shapes:\")\n",
    "for image, label in get_validation_dataset().take(3):\n",
    "    print(image.numpy().shape, label.numpy().shape)\n",
    "print(\"Validation data label examples:\", label.numpy())\n",
    "print(\"Test data shapes:\")\n",
    "for image, idnum in get_test_dataset().take(3):\n",
    "    print(image.numpy().shape, idnum.numpy().shape)\n",
    "print(\"Test data IDs:\", idnum.numpy().astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 2s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Model)          (None, 16, 16, 1920)      18321984  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 104)               199784    \n",
      "=================================================================\n",
      "Total params: 18,521,768\n",
      "Trainable params: 18,292,712\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    pretrained_model1 = tf.keras.applications.DenseNet201(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "    pretrained_model1.trainable = True # False = transfer learning, True = fine-tuning\n",
    "    \n",
    "    model1 = tf.keras.Sequential([\n",
    "        pretrained_model1,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
    "    ])\n",
    "        \n",
    "model1.compile(\n",
    "    optimizer='adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b7_noisy-student_notop.h5\n",
      "258072576/258068648 [==============================] - 3s 0us/step\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b7 (Model)      (None, 16, 16, 2560)      64097680  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 104)               266344    \n",
      "=================================================================\n",
      "Total params: 64,364,024\n",
      "Trainable params: 64,053,304\n",
      "Non-trainable params: 310,720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    pretrained_model2 = efn.EfficientNetB7(weights='noisy-student', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n",
    "    pretrained_model2.trainable = True # Full Training\n",
    "    \n",
    "    model2 = tf.keras.Sequential([\n",
    "        pretrained_model2,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
    "    ])\n",
    "        \n",
    "model2.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_START = 0.0001\n",
    "LR_MAX = 0.00005 * strategy.num_replicas_in_sync\n",
    "LR_MIN = 0.00001\n",
    "LR_RAMPUP_EPOCHS = 4\n",
    "LR_SUSTAIN_EPOCHS = 6\n",
    "LR_EXP_DECAY = .8\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = np.random.random_sample() * LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
    "    return lr\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(min_delta=0, patience=10, verbose=1, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 81 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 3.07057482207697e-05.\n",
      "Epoch 1/30\n",
      "81/81 [==============================] - 694s 9s/step - loss: 3.9157 - sparse_categorical_accuracy: 0.1956 - val_loss: 2.9501 - val_sparse_categorical_accuracy: 0.3578\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 9.970948807945198e-05.\n",
      "Epoch 2/30\n",
      "81/81 [==============================] - 120s 1s/step - loss: 1.8928 - sparse_categorical_accuracy: 0.5887 - val_loss: 1.0469 - val_sparse_categorical_accuracy: 0.7608\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 1.0318842681841934e-05.\n",
      "Epoch 3/30\n",
      "81/81 [==============================] - 120s 1s/step - loss: 1.1228 - sparse_categorical_accuracy: 0.7874 - val_loss: 0.8243 - val_sparse_categorical_accuracy: 0.8297\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 4.836258512180788e-05.\n",
      "Epoch 4/30\n",
      "81/81 [==============================] - 117s 1s/step - loss: 0.9201 - sparse_categorical_accuracy: 0.8302 - val_loss: 0.6826 - val_sparse_categorical_accuracy: 0.8578\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 5/30\n",
      "81/81 [==============================] - 122s 2s/step - loss: 0.7460 - sparse_categorical_accuracy: 0.8291 - val_loss: 1.4123 - val_sparse_categorical_accuracy: 0.6509\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 6/30\n",
      "81/81 [==============================] - 129s 2s/step - loss: 0.4611 - sparse_categorical_accuracy: 0.8889 - val_loss: 0.7809 - val_sparse_categorical_accuracy: 0.8082\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 7/30\n",
      "81/81 [==============================] - 122s 2s/step - loss: 0.3417 - sparse_categorical_accuracy: 0.9267 - val_loss: 0.6321 - val_sparse_categorical_accuracy: 0.8297\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 8/30\n",
      "81/81 [==============================] - 122s 2s/step - loss: 0.2822 - sparse_categorical_accuracy: 0.9259 - val_loss: 0.5198 - val_sparse_categorical_accuracy: 0.8621\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 9/30\n",
      "81/81 [==============================] - 121s 1s/step - loss: 0.2332 - sparse_categorical_accuracy: 0.9429 - val_loss: 0.4120 - val_sparse_categorical_accuracy: 0.9203\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 10/30\n",
      "81/81 [==============================] - 121s 1s/step - loss: 0.2125 - sparse_categorical_accuracy: 0.9456 - val_loss: 0.4783 - val_sparse_categorical_accuracy: 0.9030\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 11/30\n",
      "81/81 [==============================] - 121s 1s/step - loss: 0.1790 - sparse_categorical_accuracy: 0.9657 - val_loss: 0.4676 - val_sparse_categorical_accuracy: 0.9030\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.000322.\n",
      "Epoch 12/30\n",
      "81/81 [==============================] - 120s 1s/step - loss: 0.1448 - sparse_categorical_accuracy: 0.9664 - val_loss: 0.3532 - val_sparse_categorical_accuracy: 0.9159\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0002596000000000001.\n",
      "Epoch 13/30\n",
      "81/81 [==============================] - 120s 1s/step - loss: 0.1073 - sparse_categorical_accuracy: 0.9718 - val_loss: 0.2912 - val_sparse_categorical_accuracy: 0.9310\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.00020968000000000004.\n",
      "Epoch 14/30\n",
      "81/81 [==============================] - 120s 1s/step - loss: 0.0852 - sparse_categorical_accuracy: 0.9780 - val_loss: 0.2838 - val_sparse_categorical_accuracy: 0.9332\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.00016974400000000002.\n",
      "Epoch 15/30\n",
      "81/81 [==============================] - 120s 1s/step - loss: 0.0712 - sparse_categorical_accuracy: 0.9807 - val_loss: 0.2722 - val_sparse_categorical_accuracy: 0.9353\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.00013779520000000003.\n",
      "Epoch 16/30\n",
      "81/81 [==============================] - 120s 1s/step - loss: 0.0612 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.2643 - val_sparse_categorical_accuracy: 0.9418\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.00011223616000000004.\n",
      "Epoch 17/30\n",
      "81/81 [==============================] - 119s 1s/step - loss: 0.0531 - sparse_categorical_accuracy: 0.9884 - val_loss: 0.2582 - val_sparse_categorical_accuracy: 0.9397\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 9.178892800000003e-05.\n",
      "Epoch 18/30\n",
      "81/81 [==============================] - 119s 1s/step - loss: 0.0439 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2553 - val_sparse_categorical_accuracy: 0.9461\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 7.543114240000003e-05.\n",
      "Epoch 19/30\n",
      "81/81 [==============================] - 119s 1s/step - loss: 0.0391 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.2514 - val_sparse_categorical_accuracy: 0.9440\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 6.234491392000002e-05.\n",
      "Epoch 20/30\n",
      "81/81 [==============================] - 119s 1s/step - loss: 0.0398 - sparse_categorical_accuracy: 0.9911 - val_loss: 0.2499 - val_sparse_categorical_accuracy: 0.9504\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 5.1875931136000024e-05.\n",
      "Epoch 21/30\n",
      "81/81 [==============================] - 120s 1s/step - loss: 0.0333 - sparse_categorical_accuracy: 0.9923 - val_loss: 0.2369 - val_sparse_categorical_accuracy: 0.9461\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 4.3500744908800015e-05.\n",
      "Epoch 22/30\n",
      "81/81 [==============================] - 119s 1s/step - loss: 0.0283 - sparse_categorical_accuracy: 0.9923 - val_loss: 0.2419 - val_sparse_categorical_accuracy: 0.9440\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 3.6800595927040014e-05.\n",
      "Epoch 23/30\n",
      "81/81 [==============================] - 119s 1s/step - loss: 0.0317 - sparse_categorical_accuracy: 0.9888 - val_loss: 0.2368 - val_sparse_categorical_accuracy: 0.9461\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 3.1440476741632015e-05.\n",
      "Epoch 24/30\n",
      "81/81 [==============================] - 119s 1s/step - loss: 0.0317 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.2311 - val_sparse_categorical_accuracy: 0.9526\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 2.7152381393305616e-05.\n",
      "Epoch 25/30\n",
      "81/81 [==============================] - 119s 1s/step - loss: 0.0324 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.2328 - val_sparse_categorical_accuracy: 0.9461\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 2.3721905114644494e-05.\n",
      "Epoch 26/30\n",
      "81/81 [==============================] - 119s 1s/step - loss: 0.0294 - sparse_categorical_accuracy: 0.9931 - val_loss: 0.2359 - val_sparse_categorical_accuracy: 0.9504\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 2.0977524091715595e-05.\n",
      "Epoch 27/30\n",
      "81/81 [==============================] - 119s 1s/step - loss: 0.0322 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.2358 - val_sparse_categorical_accuracy: 0.9526\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 1.8782019273372477e-05.\n",
      "Epoch 28/30\n",
      "81/81 [==============================] - 119s 1s/step - loss: 0.0288 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.2337 - val_sparse_categorical_accuracy: 0.9526\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 1.702561541869798e-05.\n",
      "Epoch 29/30\n",
      "81/81 [==============================] - 119s 1s/step - loss: 0.0258 - sparse_categorical_accuracy: 0.9934 - val_loss: 0.2353 - val_sparse_categorical_accuracy: 0.9526\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1.5620492334958385e-05.\n",
      "Epoch 30/30\n",
      "81/81 [==============================] - 119s 1s/step - loss: 0.0269 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.2335 - val_sparse_categorical_accuracy: 0.9504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fabe0b71f28>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(get_training_dataset(), steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS, callbacks=[lr_callback], validation_data=get_validation_dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 81 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 7.08181585330989e-05.\n",
      "Epoch 1/30\n",
      "81/81 [==============================] - 526s 6s/step - loss: 4.3046 - sparse_categorical_accuracy: 0.1323 - val_loss: 3.6635 - val_sparse_categorical_accuracy: 0.3879\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 6.753965696818063e-05.\n",
      "Epoch 2/30\n",
      "81/81 [==============================] - 166s 2s/step - loss: 2.9377 - sparse_categorical_accuracy: 0.3889 - val_loss: 1.9198 - val_sparse_categorical_accuracy: 0.6164\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 7.083211276302815e-05.\n",
      "Epoch 3/30\n",
      "81/81 [==============================] - 168s 2s/step - loss: 1.7460 - sparse_categorical_accuracy: 0.6184 - val_loss: 0.9972 - val_sparse_categorical_accuracy: 0.7953\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 4.141848664784297e-05.\n",
      "Epoch 4/30\n",
      "81/81 [==============================] - 163s 2s/step - loss: 1.1865 - sparse_categorical_accuracy: 0.7458 - val_loss: 0.7159 - val_sparse_categorical_accuracy: 0.8362\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 5/30\n",
      "81/81 [==============================] - 165s 2s/step - loss: 0.7857 - sparse_categorical_accuracy: 0.8040 - val_loss: 0.4569 - val_sparse_categorical_accuracy: 0.8750\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 6/30\n",
      "81/81 [==============================] - 167s 2s/step - loss: 0.4817 - sparse_categorical_accuracy: 0.8773 - val_loss: 0.3669 - val_sparse_categorical_accuracy: 0.9095\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 7/30\n",
      "81/81 [==============================] - 161s 2s/step - loss: 0.3632 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.3043 - val_sparse_categorical_accuracy: 0.9418\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 8/30\n",
      "81/81 [==============================] - 162s 2s/step - loss: 0.2869 - sparse_categorical_accuracy: 0.9271 - val_loss: 0.2494 - val_sparse_categorical_accuracy: 0.9332\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 9/30\n",
      "81/81 [==============================] - 164s 2s/step - loss: 0.2307 - sparse_categorical_accuracy: 0.9387 - val_loss: 0.2765 - val_sparse_categorical_accuracy: 0.9332\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 10/30\n",
      "81/81 [==============================] - 167s 2s/step - loss: 0.2004 - sparse_categorical_accuracy: 0.9487 - val_loss: 0.2405 - val_sparse_categorical_accuracy: 0.9569\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 11/30\n",
      "81/81 [==============================] - 160s 2s/step - loss: 0.1720 - sparse_categorical_accuracy: 0.9576 - val_loss: 0.2275 - val_sparse_categorical_accuracy: 0.9483\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.000322.\n",
      "Epoch 12/30\n",
      "81/81 [==============================] - 162s 2s/step - loss: 0.1521 - sparse_categorical_accuracy: 0.9556 - val_loss: 0.2433 - val_sparse_categorical_accuracy: 0.9504\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0002596000000000001.\n",
      "Epoch 13/30\n",
      "81/81 [==============================] - 165s 2s/step - loss: 0.1213 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.2251 - val_sparse_categorical_accuracy: 0.9569\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.00020968000000000004.\n",
      "Epoch 14/30\n",
      "81/81 [==============================] - 162s 2s/step - loss: 0.0997 - sparse_categorical_accuracy: 0.9680 - val_loss: 0.2192 - val_sparse_categorical_accuracy: 0.9612\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.00016974400000000002.\n",
      "Epoch 15/30\n",
      "81/81 [==============================] - 159s 2s/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9761 - val_loss: 0.2198 - val_sparse_categorical_accuracy: 0.9591\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.00013779520000000003.\n",
      "Epoch 16/30\n",
      "81/81 [==============================] - 163s 2s/step - loss: 0.0707 - sparse_categorical_accuracy: 0.9842 - val_loss: 0.2135 - val_sparse_categorical_accuracy: 0.9634\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.00011223616000000004.\n",
      "Epoch 17/30\n",
      "81/81 [==============================] - 167s 2s/step - loss: 0.0668 - sparse_categorical_accuracy: 0.9784 - val_loss: 0.2133 - val_sparse_categorical_accuracy: 0.9655\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 9.178892800000003e-05.\n",
      "Epoch 18/30\n",
      "81/81 [==============================] - 158s 2s/step - loss: 0.0621 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.2146 - val_sparse_categorical_accuracy: 0.9677\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 7.543114240000003e-05.\n",
      "Epoch 19/30\n",
      "81/81 [==============================] - 161s 2s/step - loss: 0.0561 - sparse_categorical_accuracy: 0.9834 - val_loss: 0.2145 - val_sparse_categorical_accuracy: 0.9655\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 6.234491392000002e-05.\n",
      "Epoch 20/30\n",
      "81/81 [==============================] - 165s 2s/step - loss: 0.0529 - sparse_categorical_accuracy: 0.9861 - val_loss: 0.2105 - val_sparse_categorical_accuracy: 0.9655\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 5.1875931136000024e-05.\n",
      "Epoch 21/30\n",
      "81/81 [==============================] - 167s 2s/step - loss: 0.0544 - sparse_categorical_accuracy: 0.9815 - val_loss: 0.2131 - val_sparse_categorical_accuracy: 0.9655\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 4.3500744908800015e-05.\n",
      "Epoch 22/30\n",
      "81/81 [==============================] - 157s 2s/step - loss: 0.0470 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.2137 - val_sparse_categorical_accuracy: 0.9655\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 3.6800595927040014e-05.\n",
      "Epoch 23/30\n",
      "81/81 [==============================] - 162s 2s/step - loss: 0.0488 - sparse_categorical_accuracy: 0.9869 - val_loss: 0.2111 - val_sparse_categorical_accuracy: 0.9698\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 3.1440476741632015e-05.\n",
      "Epoch 24/30\n",
      "81/81 [==============================] - 165s 2s/step - loss: 0.0505 - sparse_categorical_accuracy: 0.9877 - val_loss: 0.2123 - val_sparse_categorical_accuracy: 0.9677\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 2.7152381393305616e-05.\n",
      "Epoch 25/30\n",
      "81/81 [==============================] - 167s 2s/step - loss: 0.0459 - sparse_categorical_accuracy: 0.9884 - val_loss: 0.2129 - val_sparse_categorical_accuracy: 0.9677\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 2.3721905114644494e-05.\n",
      "Epoch 26/30\n",
      "81/81 [==============================] - 157s 2s/step - loss: 0.0437 - sparse_categorical_accuracy: 0.9888 - val_loss: 0.2134 - val_sparse_categorical_accuracy: 0.9677\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 2.0977524091715595e-05.\n",
      "Epoch 27/30\n",
      "81/81 [==============================] - 163s 2s/step - loss: 0.0481 - sparse_categorical_accuracy: 0.9904 - val_loss: 0.2130 - val_sparse_categorical_accuracy: 0.9655\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 1.8782019273372477e-05.\n",
      "Epoch 28/30\n",
      "81/81 [==============================] - 166s 2s/step - loss: 0.0438 - sparse_categorical_accuracy: 0.9888 - val_loss: 0.2140 - val_sparse_categorical_accuracy: 0.9655\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 1.702561541869798e-05.\n",
      "Epoch 29/30\n",
      "81/81 [==============================] - 167s 2s/step - loss: 0.0410 - sparse_categorical_accuracy: 0.9869 - val_loss: 0.2132 - val_sparse_categorical_accuracy: 0.9655\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1.5620492334958385e-05.\n",
      "Epoch 30/30\n",
      "81/81 [==============================] - 158s 2s/step - loss: 0.0427 - sparse_categorical_accuracy: 0.9900 - val_loss: 0.2119 - val_sparse_categorical_accuracy: 0.9655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fabd314a160>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(get_training_dataset(), steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS, callbacks=[lr_callback], validation_data=get_validation_dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions...\n",
      "[ 67  28  83 ...  86 102  62]\n",
      "Generating submission.csv file...\n",
      "id,label\r\n",
      "252d840db,67\r\n",
      "1c4736dea,28\r\n",
      "c37a6f3e9,83\r\n",
      "00e4f514e,103\r\n",
      "59d1b6146,4\r\n",
      "8d808a07b,53\r\n",
      "aeb67eefb,52\r\n",
      "53cfc6586,29\r\n",
      "aaa580243,82\r\n"
     ]
    }
   ],
   "source": [
    "test_ds = get_test_dataset(ordered=True)\n",
    "\n",
    "print('Computing predictions...')\n",
    "test_images_ds = test_ds.map(lambda image, idnum: image)\n",
    "probabilities = (model1.predict(test_images_ds)*0.3)+model2.predict(test_images_ds)*0.7\n",
    "predictions = np.argmax(probabilities, axis=-1)\n",
    "print(predictions)\n",
    "\n",
    "print('Generating submission.csv file...')\n",
    "test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n",
    "test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\n",
    "np.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=['%s', '%d'], delimiter=',', header='id,label', comments='')\n",
    "!head submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
